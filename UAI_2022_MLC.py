# -*- coding: utf-8 -*-
"""Code-ML-HW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JqXrnE8ncPouPQ787Wf-vUQcbV1h13dN

MACHINE LEARNING COMPETITION
"""

!wget https://www.ics.uci.edu/~dechter/uaicompetition/2022/TuningBenchmarks/MLC.zip
!unzip /content/MLC.zip

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.multioutput import MultiOutputClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

data_directory = '/content/MLC/'
dname = 'Sample_1_MLC_2022'

f =open(data_directory+dname+'.data','r')
nvars = int(f.readline())
line = np.asarray(f.readline().split(), dtype=np.int32)

f =open(data_directory+dname+'.data','r')
x=f.readlines()

len(x)

evid_var_ids = line[1:]
evid_var_ids.shape

fpath = data_directory+dname+'.data'

f = open(fpath, "r")

nvars = int(f.readline())
print(nvars)

line = np.asarray(f.readline().split(), dtype=np.int32)
print(line)

evid_var_ids = line[1:]
print(evid_var_ids)

evid_var_ids.sort()
print(evid_var_ids)

evid_indices = range(1, evid_var_ids.shape[0]*2, 2)
print(evid_indices)

line = np.asarray(f.readline().split(), dtype=np.int32) #3
query_var_ids = line[1:]
query_indices = range(evid_var_ids.shape[0]*2+1, (evid_var_ids.shape[0]+query_var_ids.shape[0])*2, 2)

query_var_ids.sort()
print(query_var_ids)

line = np.asarray(f.readline().split(), dtype=np.int32)#4
hidden_var_ids = line[1:]

hidden_var_ids.sort()
print(hidden_var_ids)

line = f.readline()#5
nproblems = int(f.readline())#6
print(nproblems)

evid_assignments = []
query_assignments = []
weights = []

for i in range(nproblems):
    line = np.asarray(f.readline().split(), dtype=float)
    evid_assignments.append(np.asarray(line[evid_indices], dtype=np.int32))
    query_assignments.append(np.asarray(line[query_indices], dtype=np.int32))
    weights.append(line[-1])

evid_assignments = np.asarray(evid_assignments)
query_assignments = np.asarray(query_assignments)
weights = np.asarray(weights)

print(evid_assignments)

print(query_assignments)

print(evid_var_ids)

print(weights)

print(nvars)
print(len(evid_assignments[0]))
print(len(evid_var_ids))
print(len(evid_assignments))
print(len(query_assignments[0]))

matrix = []

for index in range(nproblems):
  sub_matrix = []
  for j in range(nvars):
    sub_matrix.append(j)
  k = 0
  for i in evid_var_ids:
    sub_matrix[i] = evid_assignments[index][k]
    k = k+1
  k = 0
  for i in query_var_ids:
    sub_matrix[i] = query_assignments[index][k]
    k = k+1
  for i in hidden_var_ids:
    sub_matrix[i] = -1
  matrix.append(sub_matrix)
  #print(sub_matrix)
#print(matrix)

print(matrix[0])

!git clone https://github.com/vkomaragiri/VEC.git

cd /content/VEC/

!pip install igraph
!pip install Cython

!python setup.py build_ext --inplace

from MN import MN
from BTP import BTP


mn = MN()
mn.read(data_directory+dname+'.uai')

order = np.asarray(np.arange(mn.nvars), dtype=np.int32)
np.random.shuffle(order)

print(order)

x = open(data_directory+dname+'.uai','r')
model = x.readline()
print(model)

nvars_uai = int(x.readline())
print(nvars_uai)

line = x.readline()

print(line)

domain = np.asarray(line.split(), dtype=np.int32)
print(domain)
print(len(domain))

blank = x.readline()

nfunc = int(x.readline())
print(nfunc)

functions = []
for i in range(nfunc):
  line = np.asarray(x.readline().split(), dtype=np.int32)
  functions.append(line)

print(functions)

x.readline()

func_values = []
for i in range(nfunc):
  line = np.asarray(x.readline().split(), dtype=float)
  func_values.append(line)

var2 = func_values[1]
print(var2[0])
print(var2[1])

var = functions[0]
print(len(functions))
print(var[0])
print(var[1])
print(var)
print(func_values)

def binaryToDec(n):
  return int(n,2)

dic = {2:[],4:[],6:[]}
for i in range(len(func_values)):
  val = func_values[i][0]
  dic[val].append(func_values[i][1:])

print(dic)

counter = [0]*3
full_fl = []
for i in range(len(functions)):
  final_list = []
  var = functions[i][1:]
  all_values = []

  p = 1
  for j in range(len(var)):
    p = domain[var[j]]*p

  for j in range(len(var)):
    values = []
    for k in range(nproblems):
      values.append(matrix[k][var[j]])
    all_values.append(values)

    for l in range(len(all_values[0])):
      val = []
      for x in range(len(all_values)):
        val.append(all_values[x][l])

      if -1 not in val:
        bin = int("".join(map(str, val)))

        dec = binaryToDec(str(bin))
        lis = dic[p]

        if len(lis) > counter[int(p/2)-1]:
          a = lis[counter[int(p/2)-1]]

        counter[int(p/2)-1] = counter[int(p/2)-1]+1

        final_list.append(a[dec-1])

  full_fl.append(final_list)

print(full_fl[1])

print(len(full_fl))
print(len(full_fl[1]))

new_indices = []
for i in range(nvars,len(full_fl)):
  new_indices.append(i)

print(new_indices)

# test file
t = open(data_directory+dname+'.data','a')

new_values = []
for i in range(len(full_fl)):
  if len(full_fl[i]) != 0:
    for j in new_indices:
      t.write(str(j))
      new_values.append(j)
      t.write(" ")
      t.write(str(full_fl[i][j-nvars]))
      t.write(" ")
    t.write("\n")

t.close()
f.close()

data_directory = '/content/MLC/'
dname = 'Sample_1_MLC_2022'

f1 =open(data_directory+dname+'.data','r')
nvars = int(f1.readline())
line = np.asarray(f1.readline().split(), dtype=np.int32)

f1 =open(data_directory+dname+'.data','r')
x=f1.readlines()

len(x)

class Data:
  #fpath: File path of the .data file

  #self.evid_var_ids: Contains the indices of the observed variables
  #self.query_var_ids: Contains the indices of the query variables
  #self.hidden_var_ids: Contains the indices of the hidden variables

  #self.evid_assignments: Assignments to evid variables
  #self.query_assignments: Assignments to query variables
  #self.weights: Pr(e, q)
  def __init__(self, fpath):

    f1 = open(fpath, "r")
    f1.seek(0)

    self.nvars = int(f1.readline()) #1

    line = np.asarray(f1.readline().split(), dtype=np.int32)#2
    self.evid_var_ids = line[1:]
    evid_indices = range(1, self.evid_var_ids.shape[0]*2, 2)

    line = np.asarray(f1.readline().split(), dtype=np.int32) #3
    self.query_var_ids = line[1:]
    query_indices = range(self.evid_var_ids.shape[0]*2+1, (self.evid_var_ids.shape[0]+self.query_var_ids.shape[0])*2, 2)

    line = np.asarray(f1.readline().split(), dtype=np.int32)#4
    self.hidden_var_ids = line[1:]

    line = f1.readline()#5
    self.nproblems = int(f1.readline())#6

    self.evid_assignments = []
    self.query_assignments = []
    self.weights = []
    for i in range(nproblems):
      line = np.asarray(f1.readline().split(), dtype=float)
      self.evid_assignments.append(np.asarray(line[evid_indices], dtype=np.int32))
      self.query_assignments.append(np.asarray(line[query_indices], dtype=np.int32))
      self.weights.append(line[-1])
    self.evid_assignments = np.asarray(self.evid_assignments)
    self.query_assignments = np.asarray(self.query_assignments)
    self.weights = np.asarray(self.weights)

  def convertResults(self, query_predictions):
    out = np.zeros((query_predictions.shape[0], 1+2*self.query_var_ids.shape[0]), dtype=int)
    out[:, 2::2] = query_predictions[:, :]
    out[:, 1::2] = self.query_var_ids
    out[:, 0] = self.query_var_ids.shape[0]
    return out

l = len(evid_assignments[1])
for e in full_fl:
  if len(e) != 0:
    e1 = e[:10000]
    new_evid = np.array(e1)
    evid_assignments = np.column_stack ((evid_assignments, new_evid) )
print(evid_assignments)

new_indices_numpy = np.array(new_indices)
evid_var_ids = np.append(evid_var_ids, new_indices_numpy)

print(evid_var_ids)

data = Data(data_directory+dname+'.data')

X = evid_assignments
y = query_assignments
print(X.shape)
print(y.shape)

X = evid_assignments
y = query_assignments
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)

clf = MultiOutputClassifier(LogisticRegression(max_iter=1000)).fit(X_train, y_train)

y_pred = clf.predict(X_test)

results_in_format = data.convertResults(y_pred)
np.savetxt(X=results_in_format, delimiter=' ', fmt='%d', fname=data_directory+dname+'.pred')

clf = MultiOutputClassifier(RandomForestClassifier(n_estimators = 10, max_depth=2)).fit(X_train, y_train)

y_trivial = clf.predict(X_test)

def computeLogProb(X, y):
  out = np.zeros(X.shape[0])
  for i in range(X.shape[0]):
    for j in range(X.shape[1]):
      mn.setEvidence(evid_var_ids[j], X[i][j])
    for j in range(y.shape[1]):
      mn.setEvidence(data.query_var_ids[j], y[i][j])
    btp = BTP(mn, order)
    out[i] = np.log10(btp.getPR())
  return out

def computeErr(true_ll, pred_ll):
  return np.sum(true_ll)-np.sum(pred_ll)

def computeScore(err, max_err):
  return np.max((0, 100*(1.0-err/max_err)))

y_pred = np.loadtxt(data_directory+dname+'.pred', dtype=int, delimiter=' ')[:, 1:][:, 1::2]
ntest = 10
lprob_true = computeLogProb(X_test[:ntest, :], y_test[:ntest, :])
lprob_pred = computeLogProb(X_test[:ntest, :], y_pred[:ntest, :])
lprob_trivial = computeLogProb(X_test[:ntest, :], y_trivial[:ntest, :])

err = computeErr(lprob_true, lprob_pred)
maxErr = computeErr(lprob_true, lprob_trivial)

print(err, maxErr)

print("Score:", computeScore(err, maxErr))

print(err, maxErr)

!pip freeze